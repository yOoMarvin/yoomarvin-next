export default {
  title: "Machines create UIs",
  slug: "machine-ui",
  createdAt: "December 22, 2018",
  description: "UIs in algorithms",
  category: "design",
  content: `
  **tl;dr** There are plenty of places where UIs are generated by algorithms. But the black box needs to more transparent!

2018 brought one thing: AI is everywhere 🤖. And in times where algorithms can create entire songs from scratch, there is also some room for algorithms which generate parts of digital product interfaces. Yep, sounds crazy but it’s true 😱. And actually, there are already a ton of places where you can see such things. The recommendation system of Netflix, personalized ads on Amazon, Instagram or Facebook. Or just the Siri shortcuts on iOS. The list grows and grows. Those cool things come very handy and allow a very dynamic and individual approach to the whole UX, but there are some shadows. 😈

The whole mental model behind it is a black box ◼️, that means you make some inputs (taps, watches, likes) some magic ✨ happens and then you get some outputs. And oftentimes the user does not know what happens. Furthermore, the user does not even know what are important inputs. Why am I seeing this on my feed? Why do I get that recommendation? What are the parameters that influence the output? Netflix does a pretty great job here 👍 by displaying a little sentence label like „Because you’ve watched Black Mirror…“. Here, the user exactly knows which series has had an influence on the recommendations. A bad example is Facebook 👎. Sure, some likes may play a role, but there are a ton of parameters the user does not know which make an influence on the content of the feed. Transparency and clear labels are key here! 🔑

But even if the user does know the inputs… How can you influence the output? 🤷‍♂️ It’s pretty hard to control that. A common thing to solve these problems are relevancy metrics which should say how relevant the content for the user is. If it is relevant, show it. If not, hide it. But there are also a ton of problems which come with that: Important content is hidden, not relevant content is shown or the content is simply in the wrong order. Giving the user the possibility to give feedback directly to the system is essential! 🔙

All in all, I really do like this approach to individual interfaces but creators need to make sure that the model and the algorithm is as transparent as possible and that the user really can control the content of the interface and the output of the algorithm. But damn, machines create some nice interfaces! 🚀

Keep Creating ✌️
  `
};
